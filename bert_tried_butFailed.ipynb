{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11691926,"sourceType":"datasetVersion","datasetId":7338490},{"sourceId":11692132,"sourceType":"datasetVersion","datasetId":7338624}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"3fa31ab9","cell_type":"code","source":"# Multi-task NLP Pipeline using Apache Spark (PySpark) + Full EDA + Advanced ML Model\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import Row\nfrom pyspark.sql.functions import col, when, array, length, size, lit, count, udf, concat_ws, trim, split, desc\nfrom pyspark.sql.types import ArrayType, FloatType, IntegerType, StringType\nfrom pyspark.ml.feature import StringIndexer, Tokenizer, StopWordsRemover, CountVectorizer, IDF, IndexToString, StringIndexerModel\nfrom pyspark.ml.classification import RandomForestClassifier, OneVsRest\nfrom pyspark import StorageLevel\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql import DataFrame\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport nltk\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import CountVectorizer as SklearnCountVectorizer\nfrom collections import Counter\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom sparknlp.base import DocumentAssembler\nfrom sparknlp.annotator import BertSentenceEmbeddings, ClassifierDLApproach\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import udf, col\nfrom pyspark.sql.types import StringType\nfrom pyspark.ml.feature import StringIndexer\n\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nfrom nltk.util import ngrams\nnltk.download(\"punkt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T23:31:55.169033Z","iopub.execute_input":"2025-05-05T23:31:55.169487Z","iopub.status.idle":"2025-05-05T23:31:55.183591Z","shell.execute_reply.started":"2025-05-05T23:31:55.169458Z","shell.execute_reply":"2025-05-05T23:31:55.182653Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":13},{"id":"da8879e4","cell_type":"code","source":"# Start Spark Session with memory optimizations\nspark = SparkSession.builder \\\n    .appName(\"\") \\\n    .master(\"local[*]\") \\\n    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.5.3\") \\\n    .getOrCreate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T23:31:55.185143Z","iopub.execute_input":"2025-05-05T23:31:55.185513Z","iopub.status.idle":"2025-05-05T23:31:55.205838Z","shell.execute_reply.started":"2025-05-05T23:31:55.185479Z","shell.execute_reply":"2025-05-05T23:31:55.204913Z"}},"outputs":[],"execution_count":14},{"id":"362ab82f-7aee-4488-a461-752952dfe0a4","cell_type":"code","source":"full_df = spark.read.csv(\n    \"/kaggle/input/merged-data/merged_dataset_clean.csv\",\n    header=True,\n    inferSchema=True,\n    multiLine=True,\n    escape=\"\\\"\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T23:31:55.206749Z","iopub.execute_input":"2025-05-05T23:31:55.207009Z","iopub.status.idle":"2025-05-05T23:31:55.547056Z","shell.execute_reply.started":"2025-05-05T23:31:55.206969Z","shell.execute_reply":"2025-05-05T23:31:55.546037Z"}},"outputs":[],"execution_count":15},{"id":"b65d29c6-6f4f-47ee-88f5-d06fdded43cd","cell_type":"code","source":"full_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T23:31:55.549106Z","iopub.execute_input":"2025-05-05T23:31:55.549367Z","iopub.status.idle":"2025-05-05T23:31:55.637627Z","shell.execute_reply.started":"2025-05-05T23:31:55.549350Z","shell.execute_reply":"2025-05-05T23:31:55.636566Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[Row(id='eew5j0j', text='That game hurt.', label='sadness'),\n Row(id='ed2mah1', text=\"You do right, if you don't care then fuck 'em!\", label='neutral'),\n Row(id='eeibobj', text='Man I love reddit.', label='love'),\n Row(id='eda6yn6', text='[NAME] was nowhere near them, he was by the Falcon.', label='neutral'),\n Row(id='eespn2i', text='Right? Considering it’s such an important document, I should know the damned thing backwards and forwards... thanks again for the help!', label='gratitude')]"},"metadata":{}}],"execution_count":16},{"id":"4153beba-ae59-4653-8510-5a86355415b8","cell_type":"code","source":"from pyspark.ml import Pipeline\nimport random\n\n# Prepare base stages\ndocument = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\nbert = BertSentenceEmbeddings.pretrained(\"sent_small_bert_L2_128\", \"en\") \\\n    .setInputCols([\"document\"]).setOutputCol(\"sentence_embeddings\")\n\n# Shuffle and retrain loop\nnum_rounds = 5\nbest_model = None\nbest_accuracy = 0.0\n\nfor i in range(num_rounds):\n    print(f\"\\n⚙️ Training round {i+1}/{num_rounds}\")\n    \n    # Shuffle and split\n    # Sample e.g., 30% of data, shuffle\n    sample_df = full_df.sample(withReplacement=False, fraction=0.3, seed=42)\n    shuffled_df = sample_df.orderBy(F.rand(seed=random.randint(0, 9999)))\n    train_df = shuffled_df.limit(int(shuffled_df.count() * 0.8))\n    \n    classifier = ClassifierDLApproach() \\\n        .setInputCols([\"sentence_embeddings\"]) \\\n        .setOutputCol(\"category\") \\\n        .setLabelColumn(\"label\") \\\n        .setMaxEpochs(5) \\\n        .setEnableOutputLogs(True) \\\n        .setBatchSize(32) \\\n        .setLr(0.003) \\\n        .setValidationSplit(0.2) \\\n        .setRandomSeed(random.randint(0, 9999))\n    \n    pipeline = Pipeline(stages=[document, bert, classifier])\n    model = pipeline.fit(train_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T00:21:43.636467Z","iopub.execute_input":"2025-05-06T00:21:43.636795Z","iopub.status.idle":"2025-05-06T00:35:52.702402Z","shell.execute_reply.started":"2025-05-06T00:21:43.636773Z","shell.execute_reply":"2025-05-06T00:35:52.701431Z"}},"outputs":[{"name":"stdout","text":"sent_small_bert_L2_128 download started this may take some time.\n","output_type":"stream"},{"name":"stderr","text":"25/05/06 00:21:44 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n","output_type":"stream"},{"name":"stdout","text":"Approximate size to download 16.1 MB\n[OK!]\n\n⚙️ Training round 1/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Training started - epochs: 5 - learning_rate: 0.003 - batch_size: 32 - training_examples: 18813 - classes: 31\nEpoch 1/5 - 4.61s - loss: 1921.7938 - acc: 0.20962082 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.48s\nMacro-average\t prec: 0.006721859, rec: 0.032258064, f1: 0.011125428\nMicro-average\t prec: 0.20837763, recall: 0.20837763, f1: 0.20837763\nEpoch 2/5 - 4.25s - loss: 1921.8977 - acc: 0.20978053 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.17s\nMacro-average\t prec: 0.006721859, rec: 0.032258064, f1: 0.011125428\nMicro-average\t prec: 0.20837763, recall: 0.20837763, f1: 0.20837763\nEpoch 3/5 - 4.61s - loss: 1921.8977 - acc: 0.20978053 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.16s\nMacro-average\t prec: 0.006721859, rec: 0.032258064, f1: 0.011125428\nMicro-average\t prec: 0.20837763, recall: 0.20837763, f1: 0.20837763\nEpoch 4/5 - 4.37s - loss: 1921.8977 - acc: 0.20978053 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.16s\nMacro-average\t prec: 0.006721859, rec: 0.032258064, f1: 0.011125428\nMicro-average\t prec: 0.20837763, recall: 0.20837763, f1: 0.20837763\nEpoch 5/5 - 4.30s - loss: 1921.8977 - acc: 0.20978053 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.16s\nMacro-average\t prec: 0.006721859, rec: 0.032258064, f1: 0.011125428\nMicro-average\t prec: 0.20837763, recall: 0.20837763, f1: 0.20837763\n\n⚙️ Training round 2/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Training started - epochs: 5 - learning_rate: 0.003 - batch_size: 32 - training_examples: 18813 - classes: 31\nEpoch 1/5 - 4.71s - loss: 1924.7842 - acc: 0.20923713 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.63s\nMacro-average\t prec: 0.0067904494, rec: 0.032258064, f1: 0.011219211\nMicro-average\t prec: 0.21050394, recall: 0.21050394, f1: 0.21050394\nEpoch 2/5 - 4.47s - loss: 1924.8977 - acc: 0.21008892 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.14s\nMacro-average\t prec: 0.0067904494, rec: 0.032258064, f1: 0.011219211\nMicro-average\t prec: 0.21050394, recall: 0.21050394, f1: 0.21050394\nEpoch 3/5 - 4.26s - loss: 1924.8977 - acc: 0.21008892 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.16s\nMacro-average\t prec: 0.0067904494, rec: 0.032258064, f1: 0.011219211\nMicro-average\t prec: 0.21050394, recall: 0.21050394, f1: 0.21050394\nEpoch 4/5 - 4.36s - loss: 1924.8977 - acc: 0.21008892 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.16s\nMacro-average\t prec: 0.0067904494, rec: 0.032258064, f1: 0.011219211\nMicro-average\t prec: 0.21050394, recall: 0.21050394, f1: 0.21050394\nEpoch 5/5 - 4.30s - loss: 1924.8977 - acc: 0.21008892 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.16s\nMacro-average\t prec: 0.0067904494, rec: 0.032258064, f1: 0.011219211\nMicro-average\t prec: 0.21050394, recall: 0.21050394, f1: 0.21050394\n\n⚙️ Training round 3/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Training started - epochs: 5 - learning_rate: 0.003 - batch_size: 32 - training_examples: 18813 - classes: 31\nEpoch 1/5 - 5.63s - loss: 1954.8182 - acc: 0.16334702 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.53s\nMacro-average\t prec: 0.005329474, rec: 0.032258064, f1: 0.009147633\nMicro-average\t prec: 0.16521369, recall: 0.16521369, f1: 0.16521369\nEpoch 2/5 - 4.34s - loss: 1954.8977 - acc: 0.16377291 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.17s\nMacro-average\t prec: 0.005329474, rec: 0.032258064, f1: 0.009147633\nMicro-average\t prec: 0.16521369, recall: 0.16521369, f1: 0.16521369\nEpoch 3/5 - 4.37s - loss: 1954.8977 - acc: 0.16377291 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.17s\nMacro-average\t prec: 0.005329474, rec: 0.032258064, f1: 0.009147633\nMicro-average\t prec: 0.16521369, recall: 0.16521369, f1: 0.16521369\nEpoch 4/5 - 4.37s - loss: 1954.8977 - acc: 0.16377291 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.17s\nMacro-average\t prec: 0.005329474, rec: 0.032258064, f1: 0.009147633\nMicro-average\t prec: 0.16521369, recall: 0.16521369, f1: 0.16521369\nEpoch 5/5 - 4.45s - loss: 1954.8977 - acc: 0.16377291 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.17s\nMacro-average\t prec: 0.005329474, rec: 0.032258064, f1: 0.009147633\nMicro-average\t prec: 0.16521369, recall: 0.16521369, f1: 0.16521369\n\n⚙️ Training round 4/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Training started - epochs: 5 - learning_rate: 0.003 - batch_size: 32 - training_examples: 18813 - classes: 31\nEpoch 1/5 - 4.81s - loss: 1951.7585 - acc: 0.20892873 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.53s\nMacro-average\t prec: 0.006687564, rec: 0.032258064, f1: 0.011078413\nMicro-average\t prec: 0.20731448, recall: 0.20731448, f1: 0.20731448\nEpoch 2/5 - 4.46s - loss: 1951.8977 - acc: 0.20956758 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.17s\nMacro-average\t prec: 0.006687564, rec: 0.032258064, f1: 0.011078413\nMicro-average\t prec: 0.20731448, recall: 0.20731448, f1: 0.20731448\nEpoch 3/5 - 4.54s - loss: 1951.8977 - acc: 0.20956758 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.17s\nMacro-average\t prec: 0.006687564, rec: 0.032258064, f1: 0.011078413\nMicro-average\t prec: 0.20731448, recall: 0.20731448, f1: 0.20731448\nEpoch 4/5 - 4.56s - loss: 1951.8977 - acc: 0.20956758 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.21s\nMacro-average\t prec: 0.006687564, rec: 0.032258064, f1: 0.011078413\nMicro-average\t prec: 0.20731448, recall: 0.20731448, f1: 0.20731448\nEpoch 5/5 - 4.58s - loss: 1951.8977 - acc: 0.20956758 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.17s\nMacro-average\t prec: 0.006687564, rec: 0.032258064, f1: 0.011078413\nMicro-average\t prec: 0.20731448, recall: 0.20731448, f1: 0.20731448\n\n⚙️ Training round 5/5\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Training started - epochs: 5 - learning_rate: 0.003 - batch_size: 32 - training_examples: 18813 - classes: 31\nEpoch 1/5 - 4.70s - loss: 1931.7916 - acc: 0.20983376 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.49s\nMacro-average\t prec: 0.006742436, rec: 0.032258064, f1: 0.011153597\nMicro-average\t prec: 0.20901552, recall: 0.20901552, f1: 0.2090155\nEpoch 2/5 - 4.30s - loss: 1930.8977 - acc: 0.21020642 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.16s\nMacro-average\t prec: 0.006742436, rec: 0.032258064, f1: 0.011153597\nMicro-average\t prec: 0.20901552, recall: 0.20901552, f1: 0.2090155\nEpoch 3/5 - 4.39s - loss: 1930.8977 - acc: 0.21020642 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.14s\nMacro-average\t prec: 0.006742436, rec: 0.032258064, f1: 0.011153597\nMicro-average\t prec: 0.20901552, recall: 0.20901552, f1: 0.2090155\nEpoch 4/5 - 4.67s - loss: 1930.8977 - acc: 0.21020642 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.14s\nMacro-average\t prec: 0.006742436, rec: 0.032258064, f1: 0.011153597\nMicro-average\t prec: 0.20901552, recall: 0.20901552, f1: 0.2090155\nEpoch 5/5 - 4.28s - loss: 1930.8977 - acc: 0.21020642 - batches: 588\nQuality on validation dataset (20.0%), validation examples = 4703\ntime to finish evaluation: 0.14s\nMacro-average\t prec: 0.006742436, rec: 0.032258064, f1: 0.011153597\nMicro-average\t prec: 0.20901552, recall: 0.20901552, f1: 0.2090155\n","output_type":"stream"}],"execution_count":30},{"id":"9be35a40-ac36-4f6a-a543-8710eceef375","cell_type":"code","source":"# Step 1: Predict on test data\npredictions = model.transform(test_df)\n\n# Step 2: Extract predicted label from category.result (which is an array)\nextract_pred = udf(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else \"\", StringType())\npredictions = predictions.withColumn(\"predicted_label\", extract_pred(col(\"category.result\")))\n\n# Step 3: Fit StringIndexers on both true and predicted labels\nlabel_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\").fit(predictions)\npred_indexer = StringIndexer(inputCol=\"predicted_label\", outputCol=\"predicted_label_index\").fit(predictions)\n\n# Step 4: Transform data to get numeric labels for evaluation\npredictions = label_indexer.transform(predictions)\npredictions = pred_indexer.transform(predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T00:35:52.704200Z","iopub.execute_input":"2025-05-06T00:35:52.704472Z","iopub.status.idle":"2025-05-06T00:37:30.486963Z","shell.execute_reply.started":"2025-05-06T00:35:52.704449Z","shell.execute_reply":"2025-05-06T00:37:30.485523Z"}},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":31},{"id":"db568e92-1756-413b-aa70-f92d38394e0a","cell_type":"code","source":"evaluator = MulticlassClassificationEvaluator(\n    labelCol=\"label_index\",\n    predictionCol=\"predicted_label_index\",\n    metricName=\"accuracy\"\n)\n\naccuracy = evaluator.evaluate(predictions)\nprint(\"BERT Model Accuracy:\", accuracy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T00:37:30.488321Z","iopub.execute_input":"2025-05-06T00:37:30.488723Z","iopub.status.idle":"2025-05-06T00:38:30.063888Z","shell.execute_reply.started":"2025-05-06T00:37:30.488688Z","shell.execute_reply":"2025-05-06T00:38:30.062926Z"}},"outputs":[{"name":"stderr","text":"[Stage 108:>                                                                            (0 + 1) / 1]\r","output_type":"stream"},{"name":"stdout","text":"BERT Model Accuracy: 0.19848145128414188\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":32},{"id":"622740d0-bff3-492a-bb05-46e163957f65","cell_type":"code","source":"# Create manual test samples for all 5 labels\nmanual_df = spark.createDataFrame([\n    (\"I don't want to live anymore\",),                    \n    (\"I need to talk to a therapist\",),                  \n    (\"I feel so alone lately\",),                         \n    (\"I'm constantly worried and can't relax\",),         \n    (\"Nothing excites me anymore, I'm always sad\",)      \n], [\"text\"])\n\n# Run through trained pipeline model\nmanual_preds = model.transform(manual_df)\n\n# Show the results\nmanual_preds.select(\"text\", \"category.result\").show(truncate=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T00:38:30.064906Z","iopub.execute_input":"2025-05-06T00:38:30.065229Z","iopub.status.idle":"2025-05-06T00:38:32.053516Z","shell.execute_reply.started":"2025-05-06T00:38:30.065190Z","shell.execute_reply":"2025-05-06T00:38:32.052522Z"}},"outputs":[{"name":"stderr","text":"[Stage 111:>                                                                            (0 + 3) / 3]\r","output_type":"stream"},{"name":"stdout","text":"+------------------------------------------+------------+\n|text                                      |result      |\n+------------------------------------------+------------+\n|I don't want to live anymore              |[depression]|\n|I need to talk to a therapist             |[depression]|\n|I feel so alone lately                    |[depression]|\n|I'm constantly worried and can't relax    |[depression]|\n|Nothing excites me anymore, I'm always sad|[depression]|\n+------------------------------------------+------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":33},{"id":"691f65e1","cell_type":"code","source":"spark.stop","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T00:38:32.055575Z","iopub.execute_input":"2025-05-06T00:38:32.055833Z","iopub.status.idle":"2025-05-06T00:38:32.061655Z","shell.execute_reply.started":"2025-05-06T00:38:32.055813Z","shell.execute_reply":"2025-05-06T00:38:32.060710Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<bound method SparkSession.stop of <pyspark.sql.session.SparkSession object at 0x79678355b290>>"},"metadata":{}}],"execution_count":34}]}